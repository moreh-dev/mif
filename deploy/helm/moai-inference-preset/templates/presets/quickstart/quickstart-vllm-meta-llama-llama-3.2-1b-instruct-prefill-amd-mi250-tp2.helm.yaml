apiVersion: odin.moreh.io/v1alpha1
kind: InferenceServiceTemplate
metadata:
  name: quickstart-vllm-meta-llama-llama-3.2-1b-instruct-prefill-amd-mi250-tp2
  namespace: {{ include "common.names.namespace" . }}
  labels:
    {{- include "mif.preset.labels" . | nindent 4 }}
    mif.moreh.io/model.org: meta-llama
    mif.moreh.io/model.name: llama-3.2-1b-instruct
    mif.moreh.io/role: prefill
    mif.moreh.io/accelerator.vendor: amd
    mif.moreh.io/accelerator.model: mi250
    mif.moreh.io/parallelism: tp2
spec:
  parallelism:
    tensor: 2
  template:
    spec:
      containers:
        - name: main
          image: 255250787067.dkr.ecr.ap-northeast-2.amazonaws.com/quickstart/moreh-vllm:20250915.1
          env:
            - name: ISVC_MODEL_NAME
              value: meta-llama/Llama-3.2-1B-Instruct
            - name: ISVC_EXTRA_ARGS
              value: >-
                --disable-uvicorn-access-log
                --no-enable-log-requests
                --max-model-len 16384
                --max-num-batched-tokens 8192
                --kv-transfer-config '{"kv_connector":"NixlConnector","kv_role":"kv_producer"}'
          resources:
            requests:
              amd.com/gpu: 2
            limits:
              amd.com/gpu: 2
      nodeSelector:
        moai.moreh.io/accelerator.vendor: amd
        moai.moreh.io/accelerator.model: mi250
      tolerations:
        - key: amd.com/gpu
          operator: Exists
          effect: NoSchedule